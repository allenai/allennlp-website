---
---
<!DOCTYPE html>
<html lang="en-us">
  <head>
    {% include meta.html %}
    <title>AllenNLP - DROP Dataset</title>
  </head>
  <body id="top">
    <div id="page-content">
      {% include header.html %}

      <div class="banner banner--interior-hero">
        <div class="constrained constrained--sm">
          <div class="banner--interior-hero__content">
            <h2> <b>ORB:</b> An <b>O</b>pen <b>R</b>eading <b>B</b>enchmark <br> for Comprehensive Evaluation of Machine Reading Comprehension </h2>
            <p class="t-sm">Dheeru Dua, Ananth Gottumukkala, <br> Alon Talmor, Sameer Singh and Matt Gardner<br>MRQA 2019.</p>
          </div>
        </div>
      </div>
      <div class="constrained constrained--med">

        <p>
        A lot of diverse reading comprehension datasets have recently been introduced to study various phenomena in natural language,
          ranging from simple paraphrase matching and entity typing to entity tracking and understanding the implications of the context.
          Given the availability of many such datasets, comprehensive and reliable evaluation is tedious and time-consuming.
          ORB is an evaluation server that reports performance on diverse reading comprehension datasets,
          encouraging and facilitating testing a single model's capability in understanding a wide variety of reading phenomena. It also
          includes a suite of synthetic augmentations that test model's ability to generalize to out-of-distribution syntactic structures.
        </p>

        <p>
          Find more details in the links below.
        </p>

        <li><a href="https://mrqa.github.io/assets/papers/48_Paper.pdf", target="_blank">Paper</a>, describing various tasks, synthetic augmentations and results on a baseline
          Numerically-Aware BERT (NABERT), that adds some rudimentary numerical reasoning capability, no-answer capbility along with span extraction on top of
          <a href="https://arxiv.org/pdf/1810.04805.pdf">BERT</a>.</li>

        <li><a href="https://leaderboard.allenai.org/orb", target="_blank">Leaderboard</a> with an automated docker-based evaluation on
            hidden test set.
        </li>


        <!-- TODO: enable this once we have citation
        <p><i>Citation:</i>
        <pre>
@inproceedings{Dua2019MRQA,
  author={Dheeru Dua and Ananth Gottumukkala and Alon Talmor and Sameer Singh and Matt Gardner},
  title={  {ORB}: An Open Reading Benchmark for Comprehensive Evaluation of Machine Reading Comprehension},
  booktitle={Proc. of MRQA},
  year={2019}
}
        </pre>
        </p>-->
      </div>

      {% include footer.html %}
    </div>
    {% include svg-sprite.html %}
    {% include scripts.html %}
  </body>
</html>
