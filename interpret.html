---
---
<!DOCTYPE html>
<html lang="en-us">
  <head>
    {% include meta.html %}
    <title>AllenNLP Interpret</title>
  </head>
  <body id="top">
    <div id="page-content">
      {% include header.html %}

      <div class="banner banner--interior-hero">
        <div class="constrained constrained--sm">
          <div class="banner--interior-hero__content">
            <h2>AllenNLP Interpret: A Framework for Explaining Predictions of NLP Models</h2>
            <p class="t-sm">Eric Wallace, Jens Tuyls, Junlin Wang, Sanjay Subramanian, Matt Gardner, and Sameer Singh<br>EMNLP 2019 Demo.</p>
          </div>
        </div>
      </div>
      <div class="constrained constrained--med">        
        <p>
        Despite constant advances and seemingly super-human performance on constrained domains, state-of-the-art models for NLP are imperfect. These imperfections, coupled with today's advances being driven by (seemingly black-box) neural models, leave researchers and practitioners scratching their heads, asking <i>why did my model make this prediction?</i>
        </p>

        <p>
        We present AllenNLP Interpret, a toolkit built on top of AllenNLP for interactive model interpretations. The toolkit makes it easy to apply gradient-based saliency maps and adversarial attacks to <i>new models</i>, as well as develop <i>new interpretation methods</i>. AllenNLP interpret contains three components: a suite of interpretation techniques implemented for several broad classes of models, model- and task-agnostic APIs for developing new interpretation methods (e.g., APIs to obtain input gradients), and extensible and reusable front-end components for interactive visualizations.
        </p>

        <li>A <a href="https://demo.allennlp.org/reading-comprehension", target="_blank">live demo</a> running BERT, GPT-2, and models for sentiment analysis, textual entailment, reading comprehension, and more. </li>
        
        <li>Tutorials for adding <a href="LINK", target="_blank">your model</a> to be visualized, or to add <a href="LINK", target="_blank">your interpretation method</a>.</li>

        <li>Code inside AllenNLP for computing gradients and interpreting/attacking models (<a href="https://github.com/allenai/allennlp/tree/master/allennlp/interpret", target="_blank">code</a>), and for visualizing the results in the AllenNLP demo (e.g., sentiment analysis <a href="https://github.com/allenai/allennlp-demo/blob/master/demo/src/components/demos/SentimentAnalysis.js", target="_blank">code</a>).</li>

        <li><a href="LINK", target="_blank">Paper</a>, describing the framework, the underlying technical implementation details, and some example use cases.</li>
        
        <p><i>Citation:</i>
        <pre>
        @inproceedings{Wallace2019AllenNLP,
                       Author = {Eric Wallace and Jens Tuyls and Junlin Wang and Sanjay Subramanian and Matt Gardner and Sameer Singh},
                       Booktitle = {Empirical Methods in Natural Language Processing},                            
                       Year = {2019},
                       Title = {AllenNLP Interpret: A Framework for Explaining Predictions of NLP Models}}
        </pre>
        </p>
      </div>

      {% include footer.html %}
    </div>
    {% include svg-sprite.html %}
    {% include scripts.html %}
  </body>
</html>